### Project
Developed an explainable deep reinforcement learning agent in a custom simulation environment to solve complex, multi-objective tasks with transparent decision-making.


<video width="600" controls>
  <source src="media/media1.mp4" type="video/mp4">
  Your browser does not support the video tag.
</video>



### Contributions

- Explainability through Factual and Counterfactual Analysis: By examining both factual and counterfactual actions and rewards, the project enhances the transparency of the AI agent's decision-making process. This analysis provides critical insights into why certain actions are chosen over others, allowing users to comprehend the reasoning behind specific decisions, especially in complex scenarios requiring quick responses.

- Sophisticated Reward Function Design: Developed a comprehensive reward function that balances multiple competing objectives, such as efficiency and resource management. This function integrates various factors that drive effective learning, encouraging the agent to optimize both task completion and the use of available resources.

- Implementation of a DRL Agent in a Custom Simulation Environment: Built and trained a DRL-based AI agent within a customized Pygame simulation environment to solve a complex problem with multiple objectives—navigating the environment, hitting designated targets, and appropriately avoiding or engaging enemies. The agent successfully completes the task in over 80% of trials, demonstrating robust decision-making capabilities under various scenarios.

- Comprehensive Learning Curve Analysis: Provided a detailed analysis of the agent’s learning trajectory, showcasing the progression from initial poor performance to improved efficiency in task completion. This analysis highlights how the agent refines its strategies over time, contributing to a deeper understanding of DRL learning processes.

- Advancement in Explainable AI for Multi-Objective Problems: The project demonstrates that DRL can effectively address complex, multi-objective problems. The insights gained from the reward function and decision-making analysis contribute to the broader understanding and improvement of explainability in AI-driven processes.


### Author Details
Name: Swati Kar
Email: kars@clarkson.edu

### Supervisor 
Name: Dr. Mahesh Banavar

### Installation
1. Install conda 
2. create new environment `conda env create  jetFight_`
3. Conda activate environment `conda activate jetFight_`
4. Install all dependencise `pip install -r requirements.txt`



